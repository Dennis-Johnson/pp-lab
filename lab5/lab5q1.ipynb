{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab5q1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylzlEp1LC0Tl"
      },
      "source": [
        "!apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "!apt-get remove cuda-*\n",
        "!apt autoremove\n",
        "!apt-get update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5StBjMUZDHh6"
      },
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda-9.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x32Ol4qNDeoi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8f2ad58-a291-4840-e3c7-ab92ba92f635"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OQREYQ8F8sS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f69f8a2-db95-4ec4-812c-5a50e08875d1"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-wjpi0j4f\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-wjpi0j4f\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp37-none-any.whl size=4307 sha256=492f6465d3ba4a26becce94cc15b10e0d497c355c7bc0b72d48ea2d00dd16cd5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_wee2h45/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8_8Aq97GBL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0fbfe33-cd56-456c-a187-3680bdf7a3ad"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI-39dwVFrWQ",
        "outputId": "e4456c7e-590f-4a8c-f192-89090bc1002e"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <math.h>\n",
        "#define ARR_LEN 12\n",
        "\n",
        "__global__ void add(int *a, int *b, int *c, int n) {\n",
        "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "  if(i < n)\n",
        "    c[i] = a[i] + b[i];\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  // host copies of variables a, b & c\n",
        "  int a[ARR_LEN] = {1,2,3,4,5,6,7,8,9,10,11,12};\n",
        "  int b[ARR_LEN] = {1,2,3,4,5,6,7,8,9,10,11,12};\n",
        "\n",
        "  // Separate arrays for the results of the 3 different kernel calls\n",
        "  int c1[ARR_LEN];\n",
        "  int c2[ARR_LEN];\n",
        "  int c3[ARR_LEN];\n",
        "\n",
        " \n",
        "  // device copies of variables a, b & c\n",
        "  int *d_a, *d_b, *d_c;\n",
        "\n",
        "  int size = ARR_LEN * sizeof(int);\n",
        "\n",
        "  // Allocate space for device copies of a, b, c\n",
        "  cudaMalloc((void **)&d_a, size);\n",
        "  cudaMalloc((void **)&d_b, size);\n",
        "  cudaMalloc((void **)&d_c, size);\n",
        "\n",
        "  // Copy inputs to device\n",
        "  cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "  // Launch add() kernel on GPU\n",
        "  cudaError err;\n",
        "\n",
        "  // 1a) Grid size as N  \n",
        "  add<<<ARR_LEN, 1>>>(d_a, d_b, d_c, ARR_LEN);\n",
        "  err = cudaMemcpy(&c1, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  // 1b) N threads within a block \n",
        "  add<<<1, ARR_LEN>>>(d_a, d_b, d_c, ARR_LEN);\n",
        "  err = cudaMemcpy(&c2, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  // 1c) Keep the num of threads per block as 256, vary num of blocks to handle N elements. \n",
        "  add<<<ceil(ARR_LEN/256),256>>>(d_a, d_b, d_c, ARR_LEN);\n",
        "  err = cudaMemcpy(&c3, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  if(err != cudaSuccess) \n",
        "    printf(\"CUDA error copying to Host: %s\\n\", cudaGetErrorString(err));\n",
        "  \n",
        "  printf(\"\\na) Kernel 1: \");\n",
        "  for(int i=0; i < ARR_LEN; i++)\n",
        "      printf(\"%d, \", c1[i]);\n",
        "\n",
        "  printf(\"\\nb) Kernel 2: \");\n",
        "  for(int i=0; i < ARR_LEN; i++)\n",
        "    printf(\"%d, \", c2[i]);\n",
        "\n",
        "  printf(\"\\nc) Kernel 3: \");\n",
        "  for(int i=0; i < ARR_LEN; i++)\n",
        "      printf(\"%d, \", c3[i]);\n",
        "  \n",
        "  // Cleanup\n",
        "  cudaFree(d_a);\n",
        "  cudaFree(d_b);\n",
        "  cudaFree(d_c);\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "a) Kernel 1: 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, \n",
            "b) Kernel 2: 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, \n",
            "c) Kernel 3: 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4gG6Cp3F2y9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}